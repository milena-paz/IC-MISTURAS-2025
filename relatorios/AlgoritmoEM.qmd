---
title: "O Algoritmo EM"
author: "Milena Paz Freitas"
format: html
lang: pt-BR
title-block-banner: true
title-block-style: manuscript
embed-resources: true
editor: source
theme: sandstone
html-math-method: katex
bibliography: "ref.bib"
callout-appearance: "minimal"
toc: true
toc-location: left
toc-expand: true
csl: abnt.csl
nocite: |
        @mclachlan2008
---

# 1. Introdução

O algoritmo EM é um entre vários métodos de cálculo iterativo da estimativa de máxima verossimilhança. Consiste em dois passos: o passo E (esperança) e o passo M (maximização). Um artigo de extrema importância para o desenvolvivemento e disseminação desse algoritmo foi de @dempster1977, onde foi consolidado como *"the EM algorithm"*.

A seguir serão listados dois outros algoritmos iterativos, com o propósito de realizar uma comparação com o EM:

### 1.1. Newton-Raphson

Sejam $\bm y$ vetor dos dados observados e $\bm \theta$ vetor dos parâmetros populacionais, o método de estimativa de máxima verossimilhança de $\bm \theta$ por algoritmo Newton-Raphson busca solucionar a seguinte equação:

$$
\bm{S}(\bm{\theta}|\bm{y})=\bm{0} \quad,
$$
onde $\bm S$ é a função escore (vetor gradiente da função de log-verossimilhança $l(\bm{\theta})$).

Dessa forma, dado um critério de parada, uma constante (pequena) $\varepsilon$ e valores iniciais $\hat{\bm \theta}^{(0)}$, realiza-se o seguinte:

::: {.callout-note appearance="minimal"}
1) Calcula-se o(s) próximo(s) valor(es):
$$\hat{\bm \theta}^{(k+1)}=\hat{\bm \theta}^{(k)} - H^{-1}(\hat{\bm \theta}^{(k)})\bm{S}(\hat{\bm{\theta}}^{(k)}),$$
onde $H(\bm \theta)$ é a matriz Hessiana (ou seja, matriz das derivadas parciais segundas) de $l(\bm{\theta})$.

2) Verifica-se se o critério de parada; por exemplo, se $|\hat{\theta}^{(k+1)}-\hat{\theta}^{(k)}|\leq \varepsilon$ (caso univariado). Caso seja falso, retorna-se ao passo 1.
:::

É importante notar que, no caso de $l(\bm{\theta})$ ser multimodal e  dependendo do valor inicial, o algoritmo pode convergir em um valor máximo local em vez de um máximo global. Além disso, o custo computacional deste método aumenta grandemente quanto maior o número de parâmetros for.


## 1.2 Fisher Scoring

É considerado por @mclachlan2008 como um dos métodos de Newton modificados, onde se substitui $H(\bm \theta)$ pela informação de Fisher $I(\bm \theta)=-\text{E}[H(\bm \theta)]$ (ou matriz de informação de Fisher, no caso multiparamétrico). Do mesmo ponto de partida que para o método de Newton-Raphson, temos o seguinte algoritmo:

::: {.callout-note appearance="minimal"}
1) Calcula-se o(s) próximo(s) valor(es):
$$\hat{\bm \theta}^{(k+1)}=\hat{\bm \theta}^{(k)} + I^{-1}(\hat{\bm \theta}^{(k)})\bm{S}(\hat{\bm{\theta}}^{(k)})$$


2) Verifica-se se o critério de parada. Caso seja falso, retorna-se ao passo 1.
:::

Muitas vezes $I(\bm \theta)$ não pode ser facilmente calculada, então usa-se a **matriz de informação empírica**:

$$
\begin{aligned}
I_e(\hat{\bm \theta})&=  \sum^n_{i=1} \bm{s}(y_i| \hat{\bm \theta})\bm{s}^\intercal(y_i| \hat{\bm \theta})
\\
& =-\frac{1}{n}\bm{S}(\bm{y}| \hat{\bm \theta})\bm{S}^\intercal(\bm{y}| \hat{\bm \theta}),
\end{aligned}
$$

onde $\bm{s}(y_i, \hat{\bm \theta})$ é a função escore baseada apenas na observação $y_i$.

Essa modificação do método Newton-Raphson tem custo computacional significativamente menor que o original (usando a matriz Hessiana completa), usando $I_e(\hat{\bm \theta})$ no lugar de $I(\bm \theta)$.

# 2. O algoritmo EM

É usado principalmente em casos de dados incompletos (censurados, faltantes, latentes, etc), porém **não é restrito** a esses casos. Define-se:

i. Seja $\bm{Y_{ob}}$ o vetor aleatório correspondente aos dados observados $\bm y$, com f.d.p. $f(\bm y|\bm \theta)$, onde $\bm \theta \in \Theta$ é seu vetor de parâmetros. $\bm{Y_c}=(\bm{Y_{ob}},\bm{Y_{ms}})$ é o vetor de dados completos, composto pelos dados observados e os dados acrescidos $\bm{Y_{ms}}$.

ii. Denota-se $L_c(\bm{\theta}|\bm{Y_c})=f(\bm{Y_c}|\bm \theta)$ a função de verossimilhança dos dados completos e $l_c(\bm{\theta}|\bm{Y_c})=\log [L(\bm{\theta}|\bm{Y_c})]$ a log-verossimilhança dos mesmos.

iii. Defina a função $Q$ como a esperança condicional da log-verossimilhança dos dados completos, dado os dados observados e a estimativa $\hat{\bm\theta}$: 
$$
Q(\bm \theta| \hat{\bm \theta})=
E\left[l_c(\bm{\theta}|\bm{Y_c})|\bm{Y_{ob}},\hat{\bm \theta}\right]
$$
Obs.: Muitas vezes não há uma expressão fechada para que $Q$ seja maximizada aritmeticamente, o que pode ser resolvido usando métodos numéricos.

Assim, o algoritmo é como segue:

::: {.callout-note appearance="minimal"}
1) **Passo E**: Calcula-se $Q(\bm \theta| \hat{\bm \theta}^{(k)})$;

2) **Passo M**: Obtem-se $\hat{\bm \theta}^{(k+1)}$ que maximize a função obtida no passo anterior, tal que
$$Q(\hat{\bm \theta}^{(k+1)}| \hat{\bm \theta}^{(k)})>Q(\bm \theta| \hat{\bm \theta}^{(k)})$$

3) Verifica-se se o critério de parada. Caso seja falso, retorna-se ao passo 1.
:::

## 2.1 Exemplo com a distribuição T-student Locação-Escala

::: {.callout-tip appearance="minimal"}
### Distribuição T de Student

Suponha que $T\sim t_\nu$, ou seja, $T$ seja uma variável aleatória de distribuição t-Student com $\nu$ graus de liberdade. Temos que:

$$
T=\frac{Z}{\sqrt{C/\nu}},
$$

onde $Z\sim N(0,1)$ e $C\sim \mathcal X^2_\nu$.

Note que a qui-quadrado pode ser descrita como um caso particular da distribuição gama. Ou seja, se $C\sim \mathcal X^2_\nu$, então $C \sim \text{Gamma}(\nu/2,1/2)$. Logo:

$$
T=\frac{Z}{\sqrt{U}}=ZU^{-1/2},
$$
onde $U\sim \text{Gamma}(\nu/2,\nu/2)$, já tomando em conta a operação de escala.
:::

### Distribuição T-Student Locação-Escala

Digamos que $T\sim \ell st(\mu, \sigma^2,\nu)$, com parâmetros de locação e escala $\mu \in \mathbb R$, e  $\sigma>0$. Sua densidade é dada por:

$$
f(t|\bm\theta)=
\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\sigma\sqrt{\pi\nu}}
\left(1+\frac{(t-\mu)^2}{\sigma^2\nu}\right)^{-(\nu+1)/2}, \quad t\in \mathbb R,
$$

onde $\bm \theta = (\mu,\sigma^2,\nu)^\intercal$. Podendo ser reescrita como:

$$
f(t|\bm\theta)=
\frac{k(\nu)}{\sigma}
\left(1+\frac{d^2_M(t,\mu,\sigma^2)}{\nu}\right)^{-(\nu+1)/2},
$$
onde $d_M^2(t,\mu,\sigma^2)=\frac{(t-\mu)^2}{\sigma^2}$ é quadrado da distância de Mahalanobis e $k(\nu)=\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\sqrt{\pi\nu}}$.

Além disso, se $Y \sim t_\nu$ e $T=\mu +\sigma Y$, então $T\sim \ell st(\mu,\sigma^2,\nu)$. Outras propriedades da distribuição são:

- $\text{E}(T)=\mu$, para $\nu>1$;

- $\text{Var}(T)=\sigma^2\frac{\nu}{\nu-2}$.

### Inferência por meio do Algoritmo EM

Suponha que temos uma a.a. $Y_1,..,Y_n \overset{iid}{\sim} \ell st(\mu,\sigma^2,\nu)$, onde $\nu$ é conhecido. Logo, o vetor de parâme\-tros é dado por $\bm \theta=(\mu,\sigma^2)$. Com a intenção de obter o estimador de máxima verossimilhança para $\bm \theta$, pode-se tentar pelo método tradicional:

::: {.callout-tip}

$$
L(\bm \theta |\bm y)=f(\bm y|\bm\theta)=\left(\frac{k(\nu)}{\sqrt {\sigma^2}}\right)^n
 \prod^n_{i=1}\left(1+\frac{d^2_{Mi}}{\nu}\right)^{-(\nu+1)/2},
$$

onde $d^2_{Mi}=d^2_M(y_i,\mu,\sigma^2)$.

 $$
 \Rightarrow l(\bm \theta)= n\log [k(\nu)] - \frac{n}{2}\log(\sigma^2) -\frac{\nu+1}{2}\sum^n_{i=1}log\left(1+d^2_{Mi}\nu^{-1}\right)
 $$
 
Cujas funções escores são dadas por:
 
$$
S_1(\mu)= \frac{d}{d\mu}l(\bm \theta)=\sum^n_{i=1}\left(\frac{\nu+1}{\nu +d^2_{Mi}}\right)\frac{d_{Mi}}{\sigma}
$$

$$S_2(\sigma^2)=\frac{d}{d\sigma^2}l(\bm \theta)=-\frac{n}{2\sigma^2}+\sum^n_{i=1}\left(\frac{\nu+1}{\nu+d^2_{Mi}}\right)\frac{d^2_{Mi}}{2\sigma^2}$$

Para tentar obter um estimador de máxima verossimilhança de $\bm \theta$, tradicionalmente, deve-se solucionar o sistema de equações:

$$
\begin{cases}
S_1(\mu)=0
\\
S_2(\sigma^2)=0
\end{cases},
$$

O que seria muito difícil de se fazer sem utilizar métodos iterativos (como, por exemplo, Newton-Raph\-son).
:::

Podemos estimar também esses parâmetros via Algoritmo EM, pensando no modelo t locação-escala da seguinte maneira:

- $Y_i$ pode ser reescrito da seguinte forma:
$$
Y_i = \mu + U^{-1/2}Z,
$$
onde $Z\sim N(0,\sigma^2) \perp\!\!\!\perp U\sim \text{Gama}(\nu/2,\nu/2)$.

- Assim, temos que:

$$Y_i|U_i=u_i\sim N(\mu,u_i^{-1}\sigma^2),\quad i=1,2,...,n.\quad U_i\overset{iid}\sim \text{Gama}(\nu/2,\nu/2).$$

Considerando, então $\bm y= (y_1,...,y_n)$ como o vetor de dados observados e $\bm u= (u_1,...,u_n)$, temos que o vetor de dados completos seria dado por $\bm y_c=(\bm y,\bm u)^\intercal$. Assim, temos que a função de verossimilhança dos dados completos é:

$$
L_c(\bm \theta| \bm y_c)=\frac{\prod^n_{i=1}u_i^{1/2}}{(2\pi\sigma^2)^{n/2}}
\exp\left\{ -\frac{1}{2\sigma^2}\sum^n_{i=1} u_i(y_i-\mu)^2 \right\}
\prod^n_{i=1}u^{\nu-1}\exp\left\{ -\frac{\nu}{2}\small\sum^n_{i=1} u_i \right\}
$$

$$
\Rightarrow l_c(\bm \theta)= -\frac{n}{2}\log\sigma^2-\frac{1}{2\sigma^2}\sum^n_{i=1} u_i(y_i-\mu)^2 + c(\bm u, \nu),
$$
onde $c(\bm u, \nu)=c$ é constante em relação a $\bm \theta$. Considerando $\bm{\hat\theta}^{(k)}=(\hat\mu^{(k)},{\hat\sigma^2}^{(k)})$ a estimativa de $\bm \theta$ na k-ésima iteração, formula-se a esperança condicional da log-verossimilhança completa:

$$
Q(\bm \theta| \hat{\bm \theta})= \text{E}[l_c(\bm \theta)|\bm y,\bm {\hat\theta}]=c-\frac{n \ln\sigma^2}{2}-\frac{1}{2\sigma^2}\sum^n_{i=1}\text{E}[u_i|y_i,\bm{\hat\theta}](y_i-\mu)^2
$$

Sabendo que $U|Y\sim \text{Gama}\left( \frac{\nu+1}{2}, \frac{\nu+d^2_M(y,\mu,\sigma^2)}{2} \right)$, então $\text E[u_i|y_i,\bm \theta]=\frac{\nu+1}{\nu+d^2_M}$ e:

$$
\begin{aligned}
Q(\bm \theta| \hat{\bm \theta})&=c-\frac{n \ln\sigma^2}{2}-\frac{1}{2\sigma^2}\sum^n_{i=1}\frac{\nu+1}{\nu+\frac{(y_i-\hat\mu)^2}{\hat\sigma^2}}(y_i-\mu)^2
\\
&=c-\frac{n \ln\sigma^2}{2}-\frac{1}{2\sigma^2}\sum^n_{i=1}\hat u_i(y_i-\mu)^2,
\end{aligned}
$$

onde $\hat u_i=\frac{\nu+1}{\nu+d^2_{Mi}(y_i,\hat\mu,\hat\sigma^2)}$. Logo:

*
$$
\left. \frac{dQ(\bm \theta| \hat{\bm \theta})}{d\mu} \right\vert^{\bm \mu=\bm{\hat \mu^{(k+1)}};\bm{\hat \theta}=\bm{\hat \theta^{(k)}}}
= \left.\frac{1}{\sigma^2}\sum^n_{i=1}\hat u_i(y_i-\mu) \right\vert^{\bm \mu=\bm{\hat \mu^{(k+1)}};\bm{\hat \theta}=\bm{\hat \theta^{(k)}}}=0
$$

$$
\Rightarrow \hat\mu^{(k+1)}=\frac{\sum^n_{i=1}\hat u_i^{(k)}y_i}{\sum^n_{i=1}\hat u_i^{(k)}}
$$ {#eq-mu}

*
$$
\left. \frac{dQ(\bm \theta| \hat{\bm \theta})}{d\sigma} \right\vert^{{\bm \theta}={\bm{\hat \theta}^{(k+1)}};\bm{\hat \theta}=\bm{\hat \theta^{(k)}}}=
\left. -\frac{n}{2\sigma^2}+\frac{1}{2(\sigma^2)^2}\sum^n_{i=1}\hat u_i(y_i-\mu)^2\right\vert^{{\bm \theta}={\bm{\hat \theta}^{(k+1)}};\bm{\hat \theta}=\bm{\hat \theta^{(k)}}}=0
$$

$$
\Rightarrow {\hat\sigma^2}^{(k+1)}=\frac{\sum^n_{i=1}\hat u_i^{(k)}(y_i-{\hat\mu}^{(k+1)})^2}{n}
$$ {#eq-sigma2}

Portanto, para $\nu$ conhecido, definimos o seguinte algoritmo:

::: {.callout-note appearance="minimal"}
Definido o valor inicial $\bm{\hat\theta}^{(0)}$ e um critério de parada, realiza-se o seguinte:

1) **Passo E**: Dado $\bm{\hat \theta}=\bm{\hat\theta}^{(k)}$, calcular:

$$\hat u_i^{(k)}=\frac{\nu+1}{\nu+d^2_{Mi}(y_i,\hat\mu^{(k)},{\hat\sigma^2}^{(k)})},\quad i=1,2,...,n;$$

2) **Passo M**: Obtem-se $\hat{\bm \theta}^{(k+1)}$ que maximize a função obtida no passo anterior, tal que
$$Q(\hat{\bm \theta}^{(k+1)}| \hat{\bm \theta}^{(k)})>Q(\bm \theta| \hat{\bm \theta}^{(k)})$$
Ou seja, calcula-se os pontos críticos na @eq-mu e @eq-sigma2.
:::

### Simulação do exemplo

```{r}
#fixando os parametros e tamanho amostral
n <- 30
nu <- 5
sigma2<- 6
mu <- 20

#gerando amostra t locacao-escala
y <- mu+rt(n, df=nu)*sqrt(sigma2)

l<- function(theta,u){
  -n/2*log(theta[2]) - sum(u*(y-theta[1])^2)/(2*theta[2])
}#fim funcao logverossimilhanca (somente parte dependente de theta)

#funcao de checagem de criterio de parada
crit <- function(l1,k2,u){
  abs(l1-l(k2,u)) > 1e-9
}

EM <- function(muhat,sighat ){
  cont<-1
  l1<-100
  u <- 1
  while(crit(l1,c(muhat,sighat),u)){
    #--------PASSO E--------#
    u <- (nu+1)/(nu+(y-muhat)^2/sighat)
    #-----------------------#
    l1<- l(c(muhat,sighat),u)
    #--------PASSO M--------#
    muhat <- sum(u*y)/sum(u)
    sighat <- sum(u*(y-muhat)^2)/n
    #-----------------------#
    cat("Iteração ",cont,": muhat=",muhat," sighat=",sighat,"\n")
    cont<-cont+1
  }
  return(c(mu=muhat,sigma2=sighat))
}#fim funcao algoritmo EM

# chute inicial usando media e variancia amostrais
EM(mean(y),var(y))

# chute padrao
EM(0,1)
```

## 2.2 Extensões do Algoritmo EM

Note que o exemplo 2.1 foi dado sob a suposição de que $\nu$ era fixo e conhecido, pois caso contrá\-rio o processo realizado não seria possível da forma que foi feito. Nem sempre a função $Q$ encon\-trada terá uma expressão fechada ou computacionalmente simples, o que pode tornar o algoritmo EM inviável.
Nesses casos, é possível utilizar variações do mesmo que foram formuladas para esses tipos de situação. A seguir serão apresentados as variantes ECM [@ecm] e ECME [@ecme], classificados como GEMs, algoritmos EM generalizados:

### 2.2.1 Experança-Maximização Condicional (ECM)

  No algoritmo ECM, $\bm \theta$ é subdividido em $S$ subvetores: $\bm \theta=(\bm \theta_1,...,\bm \theta_S)$; para que $Q$ seja, então, maximizada em relação a cada um dessas partições individualmente, com as demais fixadas em seu valor anterior. Ou seja, o passo M se divide em $S$ passos CM, gerando a seguinte formulação do algoritmo:
  
::: {.callout-note appearance="minimal"}
1) **Passo E**: Calcula-se $Q(\bm \theta| \hat{\bm \theta}^{(k)})$;

2) **Passos CM**: Para cada $i =1,...,S$, se faz:
    - CM-i: Fixando todos os subvetores $\bm {\hat\theta_j}^{(k)}$, $j \neq i$, busca-se um $\bm \theta_i=\bm{\hat \theta_i}^{(k+1)}$ que maximize $Q(\bm{\theta_i}| \hat{\bm \theta}_{j\neq i}^{(k)})$.
    
:::

#### Exemplo com a distribuição T-student Locação-Escala

Considerando a situação do exemplo 2.1, mas com $\nu$ desconhecido, podemos aplicar o algoritmo ECM dividindo $\bm \theta=(\bm \theta_1, \theta_2)$, onde $\bm \theta_1=(\mu,\sigma^2)$ e $\theta_2=\nu$. A log-verossimilhança para $\nu$ desconhecido é como segue:

$$
l_c(\bm \theta)=
\\
\frac{\nu}{2}\left(\sum^n_{i=1}\log u_i-\sum^n_{i=1}u_i+ n\log (\nu/2) \right)
-n\log\big[\Gamma(\nu/2)\big]-\frac{n}{2}\log\sigma^2-\frac{1}{2\sigma^2}\sum^n_{i=1} u_i(y_i-\mu)^2 + c(\bm u),
$$

onde $c(\bm u)$ é uma constante em relação a $\bm \theta$. Assim, temos que a função $Q$ é:

$$
\begin{aligned}
Q(\bm \theta| \bm{\hat\theta}^{(k)})&=
\frac{\nu}{2}\sum^n_{i=1}\left(\text E [\log u_i|\bm y, \hat \theta]-
\text E [u_i|\bm y, \hat \theta]\right)+n\left(\frac{\nu}{2}\log(\nu/2)-\log \big[\Gamma(\nu/2)\big]\right)
\\
&-\frac{n}{2}\log\sigma^2-\frac{1}{2\sigma^2}\sum^n_{i=1} \text E [u_i|\bm y, \hat \theta](y_i-\mu)^2
\end{aligned}
$$

$$
=
\frac{\nu}{2}\sum^n_{i=1}\left(\hat\ell_i^{(k)}-\hat u_i^{(k)}\right)+n\left(\frac{\nu}{2}\log(\nu/2)-\log \big[\Gamma(\nu/2)\big]\right)-\frac{n}{2}\log\sigma^2-\frac{1}{2\sigma^2}\sum^n_{i=1} \hat u_i^{(k)}(y_i-\mu)^2,
$$

onde $\hat u_i^{(k)}=\frac{\hat\nu^{(k)}+1}{\hat\nu^{(k)}+d^2_{Mi}(y_i,\hat\mu^{(k)}),{\hat\sigma^2}^{(k)})}$ e $\hat\ell_i^{(k)}$ pode ser obtido da seguinte forma:

::: {.callout-tip}
Sabendo que $U|Y\sim \text{Gama}\left( \frac{\nu+1}{2}, \frac{\nu+d^2_M(y,\mu,\sigma^2)}{2} \right)\in$ família exponencial, pode-se reescrever a sua densidade da seguinte forma:

$$
f(u|y,\bm \theta)=\frac{\left[\frac{\nu+d^2_M}{2}\right]^{\frac{\nu+1}{2}}}{\Gamma\left[(\nu+1)/2\right]}
\exp\left\{ -\frac{\nu+d^2_M}{2}u + \left[\frac{\nu+1}{2}-1\right]\log u \right\}
$$
Tomando $\eta_1=-\frac{\nu+d^2_M}{2}$ e $\eta_2=\frac{\nu+1}{2}-1$, temos que, na forma canônica:

$$
\begin{aligned}
f(u|y,\bm \eta)&=\frac{{-\eta_1}^{\eta_2+1}}{\Gamma\left[\eta_2+1\right]}
\exp\left\{ \eta_1u + \eta_2\log u \right\}
\\
&=c^*(\bm \eta)\exp\left\{ \eta_1T_1(u) + \eta_2T_2(u) \right\}
\end{aligned}
$$

A partir do resultado $\text E[T_i(x)]=-\frac{d \log c^*(\bm \eta)}{d\eta_i}$, temos que:

$$
\begin{aligned}
\hat\ell&=\text E [\log u|\bm y, \hat \theta]=\psi(\eta_2+1)-\log(-\eta_1)
\\
&=\psi[(\nu+1)/2] - \log \left(\frac{\nu+d^2_M}{2}\right),
\end{aligned}
$$
onde $\psi(\eta_2+1)=\frac{\Gamma'(\eta_2+1)}{\Gamma(\eta_2+1)}$ é a função digamma de $\eta_2+1$.

:::

O passo CM-1 seria idêntico ao passo M no exemplo 2.1, fixado um valor $\nu=\hat\nu^{(k)}$. Para o passo CM-2, temos que achar um valor $\nu^{(k+1)}$ que seja resolução da equação:

$$
\left. \frac{dQ(\bm \theta| \hat{\bm \theta})}{d\nu} \right\vert^{\bm{\hat \theta}=\bm{\hat \theta}^{(k+1)}}=0
$$

$$
\Rightarrow \frac{n}{2}\left[ \log(\hat\nu^{(k+1)}/2)+ 1-\psi(\hat\nu^{(k+1)}/2)+\frac{\sum^n_{i=1}(\hat\ell_i^{(k+1)}-\hat u_i^{(k+1)})}{n}\right]=0
$$

$$
\Rightarrow \log(\hat\nu^{(k+1)}/2)+ 1-\psi(\hat\nu^{(k+1)}/2)+\frac{\sum^n_{i=1}(\hat\ell_i^{(k+1)}-\hat u_i^{(k+1)})}{n}=0,
$$

o que pode ser encontrado através de métodos numéricos. Tem-se, então, o seguinte algoritmo:

::: {.callout-note}

- Passo E: Dado $\bm{\hat \theta}=\bm{\hat\theta}^{(k)}$, calcular:

$$\hat u_i^{(k)}=\frac{\hat\nu^{(k+1)}+1}{\hat\nu^{(k+1)}+d^2_{Mi}(y_i,\hat\mu^{(k)},{\hat\sigma^2}^{(k)})},\quad i=1,2,...,n;$$

$$
\hat\ell_i^{(k)}=\psi[(\hat\nu^{(k)}+1)/2] - \log \left(\frac{\hat\nu^{(k)}+{d^2_{Mi}}^{(k)}}{2}\right)
$$

- Passo CM-1: Obter os seguintes pontos críticos, fixado $\nu=\hat\nu^{(k)}$:

$$
\begin{aligned}
&\hat\mu^{(k+1)}=\frac{\sum^n_{i=1}\hat u_i^{(k)}y_i}{\sum^n_{i=1}\hat u_i^{(k)}}
\\
&{\hat\sigma^2}^{(k+1)}=\frac{\sum^n_{i=1}\hat u_i^{(k)}(y_i-{\hat\mu}^{(k+1)})^2}{n}
\end{aligned}
$$

- Passo CM-2: Achar um valor $\nu^{(k+1)}$ que seja resolução da equação:
$$
\log(\hat\nu^{(k+1)}/2)+ 1-\psi(\hat\nu^{(k+1)}/2)+\frac{\sum^n_{i=1}(\hat\ell_i^{(k+1)}-\hat u_i^{(k+1)})}{n}=0
$$

:::